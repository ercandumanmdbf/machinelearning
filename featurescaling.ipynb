{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e2444f-e755-4c66-8cca-4963ff6affd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe61b2cc-1d76-4d37-914d-90c976f73ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a162df-2abd-4cd9-b110-ab66c447aa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USA</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Japan</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country   Age   Salary Purchased\n",
       "0  Turkey  40.0  72000.0        No\n",
       "1     USA  27.0  48000.0       Yes\n",
       "2   Japan  30.0  54000.0        No\n",
       "3     USA  38.0  61000.0        No\n",
       "4  Turkey  40.0      NaN       Yes\n",
       "5  Turkey  35.0  58000.0       Yes\n",
       "6   Japan   NaN  52000.0        No\n",
       "7     USA  48.0  79000.0       Yes\n",
       "8  Turkey  50.0  83000.0        No\n",
       "9   Japan  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d559bc-8311-421c-b5ff-d3a41bbbc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07114780-d27d-45dc-be94-2e844fd248cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509712ff-0d3e-4c30-9642-9af707701b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:,3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294cbc9e-a849-4db1-b3b2-d5e50dc44d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.0</td>\n",
       "      <td>72000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USA</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Japan</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country   Age   Salary\n",
       "0  Turkey  40.0  72000.0\n",
       "1     USA  27.0  48000.0\n",
       "2   Japan  30.0  54000.0\n",
       "3     USA  38.0  61000.0\n",
       "4  Turkey  40.0      NaN\n",
       "5  Turkey  35.0  58000.0\n",
       "6   Japan   NaN  52000.0\n",
       "7     USA  48.0  79000.0\n",
       "8  Turkey  50.0  83000.0\n",
       "9   Japan  37.0  67000.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af7d7c1-b79d-445e-b983-0216bda96216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Purchased\n",
       "0        No\n",
       "1       Yes\n",
       "2        No\n",
       "3        No\n",
       "4       Yes\n",
       "5       Yes\n",
       "6        No\n",
       "7       Yes\n",
       "8        No\n",
       "9       Yes"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f778df5f-20cf-4452-914a-e244010c02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774ea984-38b9-41e3-ac98-b2119c521004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Turkey', 40.0, 72000.0],\n",
       "       ['USA', 27.0, 48000.0],\n",
       "       ['Japan', 30.0, 54000.0],\n",
       "       ['USA', 38.0, 61000.0],\n",
       "       ['Turkey', 40.0, nan],\n",
       "       ['Turkey', 35.0, 58000.0],\n",
       "       ['Japan', nan, 52000.0],\n",
       "       ['USA', 48.0, 79000.0],\n",
       "       ['Turkey', 50.0, 83000.0],\n",
       "       ['Japan', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf23f851-69e3-4094-b1cb-41cc4bcf437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e12a3a6-6190-4021-83ff-fa468f05b30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['No'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['No'],\n",
       "       ['Yes'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['Yes']], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f816a-93de-4a01-823d-051a691b205f",
   "metadata": {},
   "source": [
    "## now we can work on missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f7e0868-729e-403e-b09f-4f629c821814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aaf3973-f280-4b6e-90d2-f335718f4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e02f2e-b18b-4eb1-8966-43205842bd20",
   "metadata": {},
   "source": [
    "### we create a imputer value that helps to change the nan value to rows' mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689da4ba-bc75-4064-b044-f5f74daf0728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SimpleImputer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(X[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d300d205-1e0b-4b49-987e-1d0305fb1e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Turkey', 40.0, 72000.0],\n",
       "       ['USA', 27.0, 48000.0],\n",
       "       ['Japan', 30.0, 54000.0],\n",
       "       ['USA', 38.0, 61000.0],\n",
       "       ['Turkey', 40.0, 63777.77777777778],\n",
       "       ['Turkey', 35.0, 58000.0],\n",
       "       ['Japan', 38.333333333333336, 52000.0],\n",
       "       ['USA', 48.0, 79000.0],\n",
       "       ['Turkey', 50.0, 83000.0],\n",
       "       ['Japan', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,1:3] = imputer.transform(X[:,1:3])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5227c-3676-4e68-8b0e-725a73b8818d",
   "metadata": {},
   "source": [
    "#### now we change the nan values with the rows mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10264c9-ded0-43fe-b293-1acd398466b2",
   "metadata": {},
   "source": [
    "# One Hot Encoding (the method encode the string data with machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215e7b39-63d8-4d2d-95b5-34ef107c4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1df18d8d-7763-4730-8128-cfcb00a4259a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mColumnTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtransformers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mremainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'drop'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msparse_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtransformer_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose_feature_names_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Applies transformers to columns of an array or pandas DataFrame.\n",
       "\n",
       "This estimator allows different columns or column subsets of the input\n",
       "to be transformed separately and the features generated by each transformer\n",
       "will be concatenated to form a single feature space.\n",
       "This is useful for heterogeneous or columnar data, to combine several\n",
       "feature extraction mechanisms or transformations into a single transformer.\n",
       "\n",
       "Read more in the :ref:`User Guide <column_transformer>`.\n",
       "\n",
       ".. versionadded:: 0.20\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "transformers : list of tuples\n",
       "    List of (name, transformer, columns) tuples specifying the\n",
       "    transformer objects to be applied to subsets of the data.\n",
       "\n",
       "    name : str\n",
       "        Like in Pipeline and FeatureUnion, this allows the transformer and\n",
       "        its parameters to be set using ``set_params`` and searched in grid\n",
       "        search.\n",
       "    transformer : {'drop', 'passthrough'} or estimator\n",
       "        Estimator must support :term:`fit` and :term:`transform`.\n",
       "        Special-cased strings 'drop' and 'passthrough' are accepted as\n",
       "        well, to indicate to drop the columns or to pass them through\n",
       "        untransformed, respectively.\n",
       "    columns :  str, array-like of str, int, array-like of int,                 array-like of bool, slice or callable\n",
       "        Indexes the data on its second axis. Integers are interpreted as\n",
       "        positional columns, while strings can reference DataFrame columns\n",
       "        by name.  A scalar string or int should be used where\n",
       "        ``transformer`` expects X to be a 1d array-like (vector),\n",
       "        otherwise a 2d array will be passed to the transformer.\n",
       "        A callable is passed the input data `X` and can return any of the\n",
       "        above. To select multiple columns by name or dtype, you can use\n",
       "        :obj:`make_column_selector`.\n",
       "\n",
       "remainder : {'drop', 'passthrough'} or estimator, default='drop'\n",
       "    By default, only the specified columns in `transformers` are\n",
       "    transformed and combined in the output, and the non-specified\n",
       "    columns are dropped. (default of ``'drop'``).\n",
       "    By specifying ``remainder='passthrough'``, all remaining columns that\n",
       "    were not specified in `transformers`, but present in the data passed\n",
       "    to `fit` will be automatically passed through. This subset of columns\n",
       "    is concatenated with the output of the transformers. For dataframes,\n",
       "    extra columns not seen during `fit` will be excluded from the output\n",
       "    of `transform`.\n",
       "    By setting ``remainder`` to be an estimator, the remaining\n",
       "    non-specified columns will use the ``remainder`` estimator. The\n",
       "    estimator must support :term:`fit` and :term:`transform`.\n",
       "    Note that using this feature requires that the DataFrame columns\n",
       "    input at :term:`fit` and :term:`transform` have identical order.\n",
       "\n",
       "sparse_threshold : float, default=0.3\n",
       "    If the output of the different transformers contains sparse matrices,\n",
       "    these will be stacked as a sparse matrix if the overall density is\n",
       "    lower than this value. Use ``sparse_threshold=0`` to always return\n",
       "    dense.  When the transformed output consists of all dense data, the\n",
       "    stacked result will be dense, and this keyword will be ignored.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    Number of jobs to run in parallel.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "transformer_weights : dict, default=None\n",
       "    Multiplicative weights for features per transformer. The output of the\n",
       "    transformer is multiplied by these weights. Keys are transformer names,\n",
       "    values the weights.\n",
       "\n",
       "verbose : bool, default=False\n",
       "    If True, the time elapsed while fitting each transformer will be\n",
       "    printed as it is completed.\n",
       "\n",
       "verbose_feature_names_out : bool, default=True\n",
       "    If True, :meth:`get_feature_names_out` will prefix all feature names\n",
       "    with the name of the transformer that generated that feature.\n",
       "    If False, :meth:`get_feature_names_out` will not prefix any feature\n",
       "    names and will error if feature names are not unique.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "transformers_ : list\n",
       "    The collection of fitted transformers as tuples of\n",
       "    (name, fitted_transformer, column). `fitted_transformer` can be an\n",
       "    estimator, 'drop', or 'passthrough'. In case there were no columns\n",
       "    selected, this will be the unfitted transformer.\n",
       "    If there are remaining columns, the final element is a tuple of the\n",
       "    form:\n",
       "    ('remainder', transformer, remaining_columns) corresponding to the\n",
       "    ``remainder`` parameter. If there are remaining columns, then\n",
       "    ``len(transformers_)==len(transformers)+1``, otherwise\n",
       "    ``len(transformers_)==len(transformers)``.\n",
       "\n",
       "named_transformers_ : :class:`~sklearn.utils.Bunch`\n",
       "    Read-only attribute to access any transformer by given name.\n",
       "    Keys are transformer names and values are the fitted transformer\n",
       "    objects.\n",
       "\n",
       "sparse_output_ : bool\n",
       "    Boolean flag indicating whether the output of ``transform`` is a\n",
       "    sparse matrix or a dense numpy array, which depends on the output\n",
       "    of the individual transformers and the `sparse_threshold` keyword.\n",
       "\n",
       "output_indices_ : dict\n",
       "    A dictionary from each transformer name to a slice, where the slice\n",
       "    corresponds to indices in the transformed output. This is useful to\n",
       "    inspect which transformer is responsible for which transformed\n",
       "    feature(s).\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`. Only defined if the\n",
       "    underlying transformers expose such an attribute when fit.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "See Also\n",
       "--------\n",
       "make_column_transformer : Convenience function for\n",
       "    combining the outputs of multiple transformer objects applied to\n",
       "    column subsets of the original feature space.\n",
       "make_column_selector : Convenience function for selecting\n",
       "    columns based on datatype or the columns name with a regex pattern.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The order of the columns in the transformed feature matrix follows the\n",
       "order of how the columns are specified in the `transformers` list.\n",
       "Columns of the original feature matrix that are not specified are\n",
       "dropped from the resulting transformed feature matrix, unless specified\n",
       "in the `passthrough` keyword. Those columns specified with `passthrough`\n",
       "are added at the right to the output of the transformers.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.compose import ColumnTransformer\n",
       ">>> from sklearn.preprocessing import Normalizer\n",
       ">>> ct = ColumnTransformer(\n",
       "...     [(\"norm1\", Normalizer(norm='l1'), [0, 1]),\n",
       "...      (\"norm2\", Normalizer(norm='l1'), slice(2, 4))])\n",
       ">>> X = np.array([[0., 1., 2., 2.],\n",
       "...               [1., 1., 0., 1.]])\n",
       ">>> # Normalizer scales each row of X to unit norm. A separate scaling\n",
       ">>> # is applied for the two first and two last elements of each\n",
       ">>> # row independently.\n",
       ">>> ct.fit_transform(X)\n",
       "array([[0. , 1. , 0.5, 0.5],\n",
       "       [0.5, 0.5, 0. , 1. ]])\n",
       "\n",
       ":class:`ColumnTransformer` can be configured with a transformer that requires\n",
       "a 1d array by setting the column to a string:\n",
       "\n",
       ">>> from sklearn.feature_extraction import FeatureHasher\n",
       ">>> from sklearn.preprocessing import MinMaxScaler\n",
       ">>> import pandas as pd   # doctest: +SKIP\n",
       ">>> X = pd.DataFrame({\n",
       "...     \"documents\": [\"First item\", \"second one here\", \"Is this the last?\"],\n",
       "...     \"width\": [3, 4, 5],\n",
       "... })  # doctest: +SKIP\n",
       ">>> # \"documents\" is a string which configures ColumnTransformer to\n",
       ">>> # pass the documents column as a 1d array to the FeatureHasher\n",
       ">>> ct = ColumnTransformer(\n",
       "...     [(\"text_preprocess\", FeatureHasher(input_type=\"string\"), \"documents\"),\n",
       "...      (\"num_preprocess\", MinMaxScaler(), [\"width\"])])\n",
       ">>> X_trans = ct.fit_transform(X)  # doctest: +SKIP\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\users\\ercan\\anaconda31\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69e4785b-521a-400b-88ae-d58f50b152a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coltrans = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [0])],remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba550cae-a271-4316-9b15-1389eb3bd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(coltrans.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a1c5c1a-6a16-4712-9b96-339077fced3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, 40.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [1.0, 0.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [0.0, 1.0, 0.0, 35.0, 58000.0],\n",
       "       [1.0, 0.0, 0.0, 38.333333333333336, 52000.0],\n",
       "       [0.0, 0.0, 1.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcbdb4b-2f2f-4164-89b2-a2d5ed4b2dab",
   "metadata": {},
   "source": [
    "## if we use drop instead of passthrough we drop all other rows other than we work on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d1ad8-b782-43a8-a983-228ba8854f9e",
   "metadata": {},
   "source": [
    "# Label Encoding (change the variables to label 0 for no, label 1 for yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a833ea90-821a-4520-9bd8-4fcbe4680b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87b2f962-224f-44ca-a3a5-e2c3dc04b17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Encode target labels with value between 0 and n_classes-1.\n",
       "\n",
       "This transformer should be used to encode target values, *i.e.* `y`, and\n",
       "not the input `X`.\n",
       "\n",
       "Read more in the :ref:`User Guide <preprocessing_targets>`.\n",
       "\n",
       ".. versionadded:: 0.12\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : ndarray of shape (n_classes,)\n",
       "    Holds the label for each class.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "OrdinalEncoder : Encode categorical features using an ordinal encoding\n",
       "    scheme.\n",
       "OneHotEncoder : Encode categorical features as a one-hot numeric array.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "`LabelEncoder` can be used to normalize labels.\n",
       "\n",
       ">>> from sklearn import preprocessing\n",
       ">>> le = preprocessing.LabelEncoder()\n",
       ">>> le.fit([1, 2, 2, 6])\n",
       "LabelEncoder()\n",
       ">>> le.classes_\n",
       "array([1, 2, 6])\n",
       ">>> le.transform([1, 1, 2, 6])\n",
       "array([0, 0, 1, 2]...)\n",
       ">>> le.inverse_transform([0, 0, 1, 2])\n",
       "array([1, 1, 2, 6])\n",
       "\n",
       "It can also be used to transform non-numerical labels (as long as they are\n",
       "hashable and comparable) to numerical labels.\n",
       "\n",
       ">>> le = preprocessing.LabelEncoder()\n",
       ">>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
       "LabelEncoder()\n",
       ">>> list(le.classes_)\n",
       "['amsterdam', 'paris', 'tokyo']\n",
       ">>> le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
       "array([2, 2, 1]...)\n",
       ">>> list(le.inverse_transform([2, 2, 1]))\n",
       "['tokyo', 'tokyo', 'paris']\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\users\\ercan\\anaconda31\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b640e3b-6b10-41b6-9db7-a7d052a01355",
   "metadata": {},
   "outputs": [],
   "source": [
    "labenc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2b64a4a-7853-4b21-9c70-0bac97ba8510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['No'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['No'],\n",
       "       ['Yes'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['Yes'],\n",
       "       ['No'],\n",
       "       ['Yes']], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6be64471-b48f-44c5-888f-e18a104846ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labenc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9055a9c-023b-44e6-b65e-90424ac9b877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d4dba-ad72-4a7a-a24f-50652e13b419",
   "metadata": {},
   "source": [
    "# Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c94ad857-f9bb-4ce3-b310-4cf4688315b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b492d985-d790-4eeb-931f-d69e74d42e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Split arrays or matrices into random train and test subsets.\n",
       "\n",
       "Quick utility that wraps input validation,\n",
       "``next(ShuffleSplit().split(X, y))``, and application to input data\n",
       "into a single call for splitting (and optionally subsampling) data into a\n",
       "one-liner.\n",
       "\n",
       "Read more in the :ref:`User Guide <cross_validation>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*arrays : sequence of indexables with same length / shape[0]\n",
       "    Allowed inputs are lists, numpy arrays, scipy-sparse\n",
       "    matrices or pandas dataframes.\n",
       "\n",
       "test_size : float or int, default=None\n",
       "    If float, should be between 0.0 and 1.0 and represent the proportion\n",
       "    of the dataset to include in the test split. If int, represents the\n",
       "    absolute number of test samples. If None, the value is set to the\n",
       "    complement of the train size. If ``train_size`` is also None, it will\n",
       "    be set to 0.25.\n",
       "\n",
       "train_size : float or int, default=None\n",
       "    If float, should be between 0.0 and 1.0 and represent the\n",
       "    proportion of the dataset to include in the train split. If\n",
       "    int, represents the absolute number of train samples. If None,\n",
       "    the value is automatically set to the complement of the test size.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Controls the shuffling applied to the data before applying the split.\n",
       "    Pass an int for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Whether or not to shuffle the data before splitting. If shuffle=False\n",
       "    then stratify must be None.\n",
       "\n",
       "stratify : array-like, default=None\n",
       "    If not None, data is split in a stratified fashion, using this as\n",
       "    the class labels.\n",
       "    Read more in the :ref:`User Guide <stratification>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "splitting : list, length=2 * len(arrays)\n",
       "    List containing train-test split of inputs.\n",
       "\n",
       "    .. versionadded:: 0.16\n",
       "        If the input is sparse, the output will be a\n",
       "        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
       "        input type.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.model_selection import train_test_split\n",
       ">>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
       ">>> X\n",
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])\n",
       ">>> list(y)\n",
       "[0, 1, 2, 3, 4]\n",
       "\n",
       ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
       "...     X, y, test_size=0.33, random_state=42)\n",
       "...\n",
       ">>> X_train\n",
       "array([[4, 5],\n",
       "       [0, 1],\n",
       "       [6, 7]])\n",
       ">>> y_train\n",
       "[2, 0, 3]\n",
       ">>> X_test\n",
       "array([[2, 3],\n",
       "       [8, 9]])\n",
       ">>> y_test\n",
       "[1, 4]\n",
       "\n",
       ">>> train_test_split(y, shuffle=False)\n",
       "[[0, 1, 2], [3, 4]]\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\users\\ercan\\anaconda31\\lib\\site-packages\\sklearn\\model_selection\\_split.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fd7eb95-3825-48c9-882e-0829d27c13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cee11bbc-2420-4309-bac8-e0e5cbf63dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 38.333333333333336, 52000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [0.0, 1.0, 0.0, 40.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 0.0, 1.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [0.0, 1.0, 0.0, 35.0, 58000.0]], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "051134c9-a9b4-4140-b58d-f68c7f8d868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 30.0, 54000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "534f885e-d2a9-4698-a89d-82531b9d5370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e8eee1e-0019-4b3b-bbab-641ad5b60e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71735847-5cf2-47c5-9a52-60c5bf89ad70",
   "metadata": {},
   "source": [
    "## train and test functions make the machine learn before the predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a068f-e614-462f-9248-03d0c8b15085",
   "metadata": {},
   "source": [
    "### now we can make predict environment for machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87ebce-a2df-41ee-9dc9-16e27296527f",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e79daf-df63-4aa0-9e76-e5dedad586b7",
   "metadata": {},
   "source": [
    "### standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f16d6093-4c12-4831-bca5-0034abc01cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff85e01c-e6cb-463f-818f-7c3d327795e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e47192f-42db-4db5-ac25-3eb710a0ecec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38.333333333333336, 52000.0],\n",
       "       [40.0, 63777.77777777778],\n",
       "       [40.0, 72000.0],\n",
       "       [38.0, 61000.0],\n",
       "       [27.0, 48000.0],\n",
       "       [48.0, 79000.0],\n",
       "       [50.0, 83000.0],\n",
       "       [35.0, 58000.0]], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89a915db-4c3d-4bf8-9638-b4ef0fef4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,3:]=stdscl.fit_transform(X_train[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01bd7471-3145-480e-bc84-a65f64ce2ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17935780752172312, -1.0781259408412425],\n",
       "       [0.06803227181858379, -0.07013167641635372],\n",
       "       [0.06803227181858379, 0.633562432710455],\n",
       "       [-0.22883582338978492, -0.30786617274297867],\n",
       "       [-1.861610347035813, -1.420463615551582],\n",
       "       [1.2555046526520586, 1.232653363453549],\n",
       "       [1.5523727478604274, 1.5749910381638885],\n",
       "       [-0.674137966202338, -0.5646194287757332]], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "697d5086-55cb-4845-92d0-8d41f677962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:,3:]=stdscl.transform(X_test[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3504e479-42cf-4169-bfb3-d7ebc5d94847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, -1.4163082042232598, -0.9069571034860727],\n",
       "       [1.0, 0.0, 0.0, -0.3772698709939693, 0.2056403393225306]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1036ce95-db8d-4c20-a329-662781fa49cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, -0.17935780752172312, -1.0781259408412425],\n",
       "       [0.0, 1.0, 0.0, 0.06803227181858379, -0.07013167641635372],\n",
       "       [0.0, 1.0, 0.0, 0.06803227181858379, 0.633562432710455],\n",
       "       [0.0, 0.0, 1.0, -0.22883582338978492, -0.30786617274297867],\n",
       "       [0.0, 0.0, 1.0, -1.861610347035813, -1.420463615551582],\n",
       "       [0.0, 0.0, 1.0, 1.2555046526520586, 1.232653363453549],\n",
       "       [0.0, 1.0, 0.0, 1.5523727478604274, 1.5749910381638885],\n",
       "       [0.0, 1.0, 0.0, -0.674137966202338, -0.5646194287757332]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cbdb8b-fe9a-4a92-be5c-cc155f4a3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make the numbers meaningfull for machine no matter how big or small they"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
